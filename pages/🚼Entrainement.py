import streamlit as st



def afficher_tutoriel():


# Configuration de la page
    st.set_page_config(
        page_title="Mon Application Streamlit",
        page_icon=":rocket:",
    )

    st.header(':blue[üòÄCommen√ßons!]')
    st.info("Pour atteindre cet objectif, nous allons proc√©der comme suit : nous cr√©erons un nouveau notebook sur Kaggle, d√©finirons la langue comme Python et l'acc√©l√©rateur comme GPU. Ensuite, nous suivrons les √©tapes √©num√©r√©es ci-dessous :")
     
    st.subheader("√âtape 1 : Importation des biblioth√®ques n√©cessaires")
    st.write("Assurez-vous d'avoir les biblioth√®ques n√©cessaire. Vous pouvez le charger comme ceci :")
    """```python
    from sklearn.model_selection import train_test_split 
    import pandas as pd 
    import string 
    import re
    """

    st.subheader("√âtape 2 : Chargement des donn√©es")
    st.write("Nous chargeons les donn√©es √† partir du fichier 'data.csv' et s√©lectionnons les donn√©es correspondant √† la langue 'Fon'.")
    """```python df = pd.read_csv('data.csv')

    df_fon = df[df['Target_Language'] == 'Fon']"""

    st.subheader("√âtape 3 : Affichage des premi√®res lignes du DataFrame")
    st.write("Nous allons maintenant afficher les premi√®res lignes du DataFrame cr√©er pr√©cedemment √† l'aide de vos donn√©es.")

    """```python df_fon_head = df_fon.head()
    st.write(df_fon_head)"""

    st.subheader("√âtape 4 : Pr√©traitement des donn√©es")
    st.write("Nous allons maintenant effectuer le pr√©traitement des donn√©es.")

    """```python 
    
    # Conversion de toutes les lettres en minuscules
    df_fon['Target'] = df_fon['Target'].apply(lambda x: str(x).lower())
    df_fon['French'] = df_fon['French'].apply(lambda x: str(x).lower())

    # Suppression des apostrophes des phrases
    df_fon['Target'] = df_fon['Target'].apply(lambda x: re.sub("'", "", x))
    df_fon['French'] = df_fon['French'].apply(lambda x: re.sub("'", "", x))

    # Suppression de toute ponctuation
    exclude = set(string.punctuation)
    df_fon['Target'] = df_fon['Target'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))
    df_fon['French'] = df_fon['French'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))

    # Suppression des chiffres des phrases
    digit = str.maketrans('', '', string.digits)
    df_fon['Target'] = df_fon['Target'].apply(lambda x: x.translate(digit))
    df_fon['French'] = df_fon['French'].apply(lambda x: x.translate(digit))

    # Affichage des premi√®res lignes du DataFrame apr√®s pr√©traitement
    st.write("Voici les premi√®res lignes du DataFrame apr√®s pr√©traitement :")
    st.write(df_fon.head())"""

    st.write("Nous aurons en sortie:")
    st.success("""
    /tmp/ipykernel_34/2459096507.py:4: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame.
    Try using .loc[row_indexer,col_indexer] = value instead

    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
    df_fon['Target'] = df_fon['Target'].apply(lambda x: str(x).lower())
    /tmp/ipykernel_34/2459096507.py:5: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame.
    Try using .loc[row_indexer,col_indexer] = value instead

    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
    df_fon['French'] = df_fon['French'].apply(lambda x: str(x).lower())
    /tmp/ipykernel_34/2459096507.py:8: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame.
    Try using .loc[row_indexer,col_indexer] = value instead

    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
    df_fon['Target'] = df_fon['Target'].apply(lambda x: re.sub("'","",x))
    /tmp/ipykernel_34/2459096507.py:9: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame.
    Try using .loc[row_indexer,col_indexer] = value instead

    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
    df_fon['French'] = df_fon['French'].apply(lambda x: re.sub("'","",x))
    /tmp/ipykernel_34/2459096507.py:13: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame.
    Try using .loc[row_indexer,col_indexer] = value instead

    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
    df_fon['Target'] = df_fon['Target'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))
    /tmp/ipykernel_34/2459096507.py:14: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame.
    Try using .loc[row_indexer,col_indexer] = value instead

    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
    df_fon['French'] = df_fon['French'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))
    /tmp/ipykernel_34/2459096507.py:18: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame.
    Try using .loc[row_indexer,col_indexer] = value instead

    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
    df_fon['Target'] = df_fon['Target'].apply(lambda x: x.translate(digit))
    /tmp/ipykernel_34/2459096507.py:19: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame.
    Try using .loc[row_indexer,col_indexer] = value instead

    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
    df_fon['French'] = df_fon['French'].apply(lambda x: x.translate(digit))
""")
    
    st.subheader("√âtape 5 : Division des donn√©es en ensembles d'entra√Ænement, de validation et de test")
    st.write("Nous allons maintenant diviser les donn√©es en ensembles d'entra√Ænement, de validation et de test.")

    """```python
    
    # Division des donn√©es en ensemble d'entra√Ænement et le reste 
    train_data, rest_data = train_test_split(df_fon, test_size=0.3, random_state=42)

    # Division du reste en ensembles de validation et de test
    validation_data, test_data = train_test_split(rest_data, test_size=0.5, random_state=42)
    """
    st.success("test_size=0.3 signifie que les donn√©es sont divis√©s avec 70% pour les donn√©es d'entrainement et 30% pour le reste. test_size=0.5 montre que le reste √©t√© diviser en deux pour les donn√©e de validation et de test")

    st.subheader("√âtape 6 : G√©n√©ration des fichiers texte")
    st.write("Les fichiers texte pour l'ensemble d'entra√Ænement, de validation et de test ont √©t√© g√©n√©r√©s avec succ√®s.")
    """```python
    def text_to_file(_df,filename):
    french_texts = _df['French']
    target_texts = _df['Target']

    with open(f"{filename}.fr", 'w') as file:
        # file.writelines(french_texts)
        for text in french_texts:
            file.write(text + '\n')

    with open(f"{filename}.fon", 'w') as file:
        # file.writelines(target_texts)
        for text in target_texts:
            file.write(text + '\n')

text_to_file(train_data,'train')
text_to_file(validation_data,'validation')
text_to_file(test_data,'test')
    """
    
    st.subheader("√âtape 7 : Clonage du r√©f√©rentiel Fairseq (√† faire manuellement)")
    st.write("Vous devez cloner manuellement le r√©f√©rentiel Fairseq depuis GitHub.")
    """```python
    !git clone https://github.com/pytorch/fairseq
    """

    st.subheader("√âtape 8 : Exploration du contenu du r√©pertoire Fairseq (apr√®s clonage)")
    st.write("Une fois que vous avez clon√© le r√©f√©rentiel Fairseq, vous pouvez explorer son contenu.")
    """```python
    !ls fairseq/
    """

    st.subheader("√âtape 9 : Installation de Fairseq (apr√®s clonage)")
    st.write("Une fois que vous avez clon√© le r√©f√©rentiel Fairseq, vous pouvez l'installer localement.")

    st.write("Pour installer Fairseq, assurez-vous d'√™tre dans le r√©pertoire o√π vous avez clon√© Fairseq.")

    st.write("Ensuite, vous pouvez ex√©cuter la commande suivante dans votre terminal :")
    st.code("!pip install --editable ./fairseq/. --user", language="shell")

    st.write("Cela installera Fairseq localement sur votre syst√®me.")

    st.subheader("√âtape 10 : Pr√©traitement et binarisation des donn√©es avec Fairseq")
    st.write("Une fois que vous avez install√© Fairseq localement et organis√© vos donn√©es, vous pouvez les pr√©traiter et les binariser.")

    st.write("Pour pr√©traiter et binariser les donn√©es avec Fairseq, vous pouvez ex√©cuter la commande suivante dans votre terminal :")
    st.code("!~/.local/bin/fairseq-preprocess --source-lang fon --target-lang fr \
        --trainpref data/train --validpref data/validation --testpref data/test \
        --destdir data-bin/fonfr.tokenized.fon-fr \
        --workers 20", language="shell")

    st.write("Assurez-vous d'√™tre dans le r√©pertoire appropri√© o√π se trouvent vos donn√©es.")
    st.write("Cela pr√©traitera et binarisera vos donn√©es pour qu'elles soient pr√™tes √† √™tre utilis√©es avec Fairseq.")

    st.subheader("√âtape 11 : Installation des biblioth√®ques FastBPE, SacreMoses et Subword NMT")
    st.write("Vous pouvez installer les biblioth√®ques FastBPE, SacreMoses et Subword NMT en ex√©cutant la commande suivante dans votre terminal :")
    st.code("!pip install fastBPE sacremoses subword_nmt", language="shell")

    st.write("Cela installera les biblioth√®ques n√©cessaires pour votre projet.")

    st.subheader("Entra√Ænement du mod√®le")
    st.write("Pour entra√Æner votre mod√®le, vous pouvez ex√©cuter la commande suivante dans votre terminal :")

    """```python
    !CUDA_VISIBLE_DEVICES=0
    !~/.local/bin/fairseq-train \
        data-bin/fonfr.tokenized.fon-fr \
        --arch transformer --share-decoder-input-output-embed \
        --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 \
        --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \
        --dropout 0.3 --weight-decay 0.0001 \
        --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \
        --max-tokens 4096 \
        --eval-bleu \
        --no-epoch-checkpoints \
        --eval-bleu-args '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}' \
        --eval-bleu-detok moses \
        --eval-bleu-remove-bpe \
        --eval-bleu-print-samples \
        --best-checkpoint-metric bleu --maximize-best-checkpoint-metric \
        --max-epoch 500"""

    
    st.info("Astuce : Pour √©viter que votre entra√Ænement ne soit interrompu lorsque vous passez √† autre chose, il vous suffit d'appuyer sur le bouton 'Enregistrer' sur la page, de s√©lectionner le notebook sur lequel vous travaillez. Ensuite, une ic√¥ne appara√Ætra en bas de la page que vous pourrez utiliser pour ajouter votre notebook, et gr√¢ce au menu du bouton √† trois points juste √† c√¥t√©, relancer l'entra√Ænement. Ce nouvel entra√Ænement ne s'arr√™tera pas tant que l'entra√Ænement initial se poursuivra.")
    st.success("T√©lecharger √† la fin au niveau du output le fichier checkpoint_best.pt et stocker le sur drive.")
    st.subheader("F√©licitation!üëç, vous venez d'entrainer votre mod√®leü•≥. ")





if __name__ == "__main__":
    afficher_tutoriel()
